{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Behavioral_Cloning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilvjose/Behavioral-Cloning/blob/master/Behavioral_Cloning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nRLigMnl1_XD",
        "colab_type": "code",
        "outputId": "d16edd65-ed47-4b64-99fd-b64dedeaac40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Running setup.py bdist_wheel for wget ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a0PJKKNHjp1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import wget\n",
        "import zipfile\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2MjrI28CkH5c",
        "colab_type": "code",
        "outputId": "761b4e9e-1d14-4e98-84a3-c159f2aec829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "wget.download(\"https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "M6NRNx35kRjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "joS9YZEKSBR6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "4XVc24nAs27D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/rslim087a/track.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B8xOaHyrtImE",
        "colab_type": "code",
        "outputId": "013b3ef9-eab3-4bf8-fe73-ac43dca2b534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls data/data\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "driving_log.csv  IMG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4r7-q8d8vV1X",
        "colab_type": "code",
        "outputId": "71629765-6cec-43eb-832f-0a8aeb3b3c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential, model_from_json, load_model\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, Lambda, Cropping2D, ELU\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from scipy.misc import imread, imsave\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CPCqBPBa2Bs1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_image(csv_line, data):\n",
        "  positions=['left','center','right']\n",
        "  corrections=[0.25, 0 ,-0.25] \n",
        "  index = data.index[csv_line]\n",
        "  r=random.choice([0,1,2])\n",
        "  measurement = data['steering'][index]+corrections[r]\n",
        "  path = PATH + data[positions[r]][index][1:]\n",
        "  if r == 1: path = PATH + data[positions[r]][index]\n",
        "  image = imread(path)\n",
        "  if random.random() > 0.5:\n",
        "    image, measurement = np.fliplr(image), -measurement\n",
        "  return image, measurement"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azGxPsaDIEaw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(csv_data, batch_size):\n",
        "\n",
        "  while True:\n",
        "\n",
        "    num_data = len(csv_data)\n",
        "    positions=['left','center','right']\n",
        "    corrections=[0.25, 0 ,-0.25]\n",
        "    #csv_data.sample(frac=1)\n",
        "    # itrate through batches\n",
        "    for start in range(0, num_data, batch_size):\n",
        "      images, measurements = [], []\n",
        "      # itrate inside the batch\n",
        "      for csv_line in range(start, start + batch_size):\n",
        "        if csv_line < num_data:\n",
        "          index = csv_data.index[csv_line]\n",
        "          r=random.choice([0,1,2])\n",
        "          measurement = csv_data['steering'][index]+corrections[r] # assing random corrections to angle (under steering head)\n",
        "          path = PATH + csv_data[positions[r]][index][1:] # left, right\n",
        "          if r == 1:path = PATH + csv_data[positions[r]][index] #center\n",
        "          image = imread(path)\n",
        "          if random.random() > 0.5:\n",
        "            measurements.append(-measurement) #flip measurement\n",
        "            images.append(np.fliplr(image)) #flip image\n",
        "\n",
        "      yield np.array(images), np.array(measurements)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sICWLDyRBNxG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_samples(csv_data, batch_size):\n",
        "\n",
        "  while True:\n",
        "\n",
        "    num_data = len(csv_data)\n",
        "    #csv_data.sample(frac=1)\n",
        "    # itrate through batches\n",
        "    for start in range(0, num_data, batch_size):\n",
        "      images, measurements = [], []\n",
        "      # itrate inside the batch\n",
        "      for csv_line in range(start, start + batch_size):\n",
        "        if csv_line < num_data:\n",
        "          image, measurement = get_image(csv_line, csv_data)\n",
        "          measurements.append(measurement)\n",
        "          images.append(image)\n",
        "\n",
        "      yield np.array(images), np.array(measurements)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5WpKjRPHjRv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGcFVPXEBQ-0",
        "colab_type": "code",
        "outputId": "8915b6dd-788d-4b55-c5b3-5449309b8c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Lambda(lambda x: (x / 255) - 0.5, input_shape = (160, 320, 3)))\n",
        "model.add(Cropping2D(cropping=((70, 25), (0, 0)), input_shape = (160, 320, 3)))\n",
        "model.add(Convolution2D(16, 8, 8, subsample = (4, 4), border_mode = \"same\"))\n",
        "model.add(ELU())\n",
        "model.add(Convolution2D(32, 5, 5, subsample = (2, 2), border_mode = \"same\"))\n",
        "model.add(ELU())\n",
        "model.add(Convolution2D(32, 5, 5, subsample = (2, 2), border_mode = \"same\"))\n",
        "model.add(ELU())\n",
        "model.add(Convolution2D(64, 5, 5, subsample = (2, 2), border_mode = \"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(.2))\n",
        "model.add(ELU())\n",
        "model.add(Dense(512))\n",
        "model.add(Dropout(.5))\n",
        "model.add(ELU())\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer = \"adam\", loss = \"mse\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_2 (Lambda)            (None, 160, 320, 3)       0         \n",
            "_________________________________________________________________\n",
            "cropping2d_2 (Cropping2D)    (None, 65, 320, 3)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 17, 80, 16)        3088      \n",
            "_________________________________________________________________\n",
            "elu_7 (ELU)                  (None, 17, 80, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 9, 40, 32)         12832     \n",
            "_________________________________________________________________\n",
            "elu_8 (ELU)                  (None, 9, 40, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 20, 32)         25632     \n",
            "_________________________________________________________________\n",
            "elu_9 (ELU)                  (None, 5, 20, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 3, 10, 64)         51264     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "elu_10 (ELU)                 (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               983552    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "elu_11 (ELU)                 (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,076,881\n",
            "Trainable params: 1,076,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (8, 8), strides=(4, 4), padding=\"same\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), strides=(2, 2), padding=\"same\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), strides=(2, 2), padding=\"same\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BqwD5asSBURS",
        "colab_type": "code",
        "outputId": "fc80445f-78b2-4ef8-a12f-ab15b857a2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 25\n",
        "PATH = \"data/data/\"\n",
        "csv_name = \"driving_log.csv\"\n",
        "\n",
        "X_data = pd.read_csv(PATH + csv_name, usecols = [0, 1, 2, 3])\n",
        "\n",
        "X_train, X_valid = train_test_split(X_data, test_size = 0.20)\n",
        "num_train = len(X_train)\n",
        "num_valid = len(X_valid)\n",
        "X_data.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>center</th>\n",
              "      <th>left</th>\n",
              "      <th>right</th>\n",
              "      <th>steering</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   center  \\\n",
              "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
              "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
              "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
              "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
              "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
              "\n",
              "                                    left  \\\n",
              "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
              "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
              "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
              "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
              "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
              "\n",
              "                                    right  steering  \n",
              "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0  \n",
              "1   IMG/right_2016_12_01_13_30_48_404.jpg       0.0  \n",
              "2   IMG/right_2016_12_01_13_31_12_937.jpg       0.0  \n",
              "3   IMG/right_2016_12_01_13_31_13_037.jpg       0.0  \n",
              "4   IMG/right_2016_12_01_13_31_13_177.jpg       0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "jurODbJcwnpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rT98_lOc0kR3",
        "colab_type": "code",
        "outputId": "18cfbd4f-742c-4f26-e99d-599ac80cc2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "num_bins=25\n",
        "measurement = X_data['steering']\n",
        "hist,bins=np.histogram(measurement,num_bins)\n",
        "centered= (bins[-1]+bins[1:])*0.5\n",
        "plt.bar(centered,hist,width=0.03)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Container object of 25 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f89be482a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "V_GIe7kqBXVb",
        "colab_type": "code",
        "outputId": "4cd17b0b-0097-44a7-ab90-08a40db4282d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        }
      },
      "cell_type": "code",
      "source": [
        "print('Training model...')\n",
        "\n",
        "training_generator = generate_samples(X_train, batch_size)\n",
        "validation_generator = generate_samples(X_valid, batch_size)\n",
        "\n",
        "\n",
        "\n",
        "history_object = model.fit_generator(training_generator,\n",
        "                 samples_per_epoch = int(num_train/batch_size),\n",
        "                 #samples_per_epoch = num_train,\n",
        "                 validation_data = validation_generator,\n",
        "                 nb_val_samples = int (num_valid/batch_size),\n",
        "                 #nb_val_samples = num_valid,\n",
        "                 nb_epoch = epochs,\n",
        "                 verbose = 1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., verbose=1, steps_per_epoch=100, epochs=25, validation_steps=25)`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0244 - val_loss: 0.0224\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0227 - val_loss: 0.0228\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0222 - val_loss: 0.0214\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0224 - val_loss: 0.0241\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0226 - val_loss: 0.0203\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0222 - val_loss: 0.0214\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0219 - val_loss: 0.0226\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0207 - val_loss: 0.0219\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0207 - val_loss: 0.0231\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0206 - val_loss: 0.0221\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0201 - val_loss: 0.0198\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0191 - val_loss: 0.0247\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0213 - val_loss: 0.0242\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0190 - val_loss: 0.0193\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0186 - val_loss: 0.0204\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0188 - val_loss: 0.0197\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0189 - val_loss: 0.0233\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0183 - val_loss: 0.0213\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0191 - val_loss: 0.0247\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0187 - val_loss: 0.0222\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0185 - val_loss: 0.0224\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0176 - val_loss: 0.0236\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0182 - val_loss: 0.0210\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0177 - val_loss: 0.0182\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0172 - val_loss: 0.0177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CZSdU7L1GM9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index = random.randint(0, len(X_train))\n",
        "image = X_train[index].squeeze()\n",
        "\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(image)\n",
        "print(y_train[index])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}